opts_month$elements[[x]]$clickElement() # select a different month in each lapply iteration
Sys.sleep(10) # for submit button to become active
webElem_submit <- remDr$findElement(using = "css", "#cphBody_But_Submit")
webElem_submit$clickElement()
page_source <- remDr$getPageSource()
tdf <- read_html(page_source[[1]]) %>%     # read table
html_nodes("table") %>% .[[5]] %>%
html_table(header=T,fill=T, trim=T) %>%
head(-1) # remove the last row which contains average at the bottom of the scraped table
})
remDr$close()
rD$server$stop()
# lst is a list, with 12 elements. Each element corresponds to data for one month of 2016
rm(list=ls())
library(RSelenium)
library(rvest)
library(tidyverse)
url <- "http://agmarknet.gov.in/PriceTrends/SA_Month_PriMar.aspx"
rD <- remoteDriver()
remDr <- rD
lst <- lapply(seq(2,13), function(x) {
remDr$navigate(url)
webElem_commodity <- remDr$findElement(using = "css", "#cphBody_Commodit_list")
opts_commodity <- webElem_commodity$selectTag() # get all the associated tags
commodity_num <- which(opts_commodity$text=="Tomato") # find the required option
opts_commodity$elements[[commodity_num]]$clickElement() # select the required option
Sys.sleep(10) # for state names to load
webElem_state <- remDr$findElement(using = "css", "#cphBody_State_list")
opts_state <- webElem_state$selectTag()
state_num <- which(opts_state$text=="Karnataka")
opts_state$elements[[state_num]]$clickElement()
Sys.sleep(10) # for years to load
webElem_yr <- remDr$findElement(using = "css", "#cphBody_Yea_list")
opts_yr <- webElem_yr$selectTag()
yr_num <- which(opts_yr$text=="2016")
opts_yr$elements[[yr_num]]$clickElement()
Sys.sleep(10) # for months to load
webElem_month <- remDr$findElement(using = "css", "#cphBody_Mont_list")
opts_month <- webElem_month$selectTag()
opts_month$elements[[x]]$clickElement() # select a different month in each lapply iteration
Sys.sleep(10) # for submit button to become active
webElem_submit <- remDr$findElement(using = "css", "#cphBody_But_Submit")
webElem_submit$clickElement()
page_source <- remDr$getPageSource()
tdf <- read_html(page_source[[1]]) %>%     # read table
html_nodes("table") %>% .[[5]] %>%
html_table(header=T,fill=T, trim=T) %>%
head(-1) # remove the last row which contains average at the bottom of the scraped table
})
remDr$close()
rD$server$stop()
# lst is a list, with 12 elements. Each element corresponds to data for one month of 2016
rD <- r
url <- "http://agmarknet.gov.in/PriceTrends/SA_Month_PriMar.aspx"
rD <- rsDriver()
remDr <- rD$client
library(RSelenium)
library(rvest)
library(tidyverse)
url <- "http://agmarknet.gov.in/PriceTrends/SA_Month_PriMar.aspx"
rD <- rsDriver()
remDr <- rD$client
lst <- lapply(seq(2,13), function(x) {
remDr$navigate(url)
webElem_commodity <- remDr$findElement(using = "css", "#cphBody_Commodit_list")
opts_commodity <- webElem_commodity$selectTag() # get all the associated tags
commodity_num <- which(opts_commodity$text=="Tomato") # find the required option
opts_commodity$elements[[commodity_num]]$clickElement() # select the required option
Sys.sleep(10) # for state names to load
webElem_state <- remDr$findElement(using = "css", "#cphBody_State_list")
opts_state <- webElem_state$selectTag()
state_num <- which(opts_state$text=="Karnataka")
opts_state$elements[[state_num]]$clickElement()
Sys.sleep(10) # for years to load
webElem_yr <- remDr$findElement(using = "css", "#cphBody_Yea_list")
opts_yr <- webElem_yr$selectTag()
yr_num <- which(opts_yr$text=="2016")
opts_yr$elements[[yr_num]]$clickElement()
Sys.sleep(10) # for months to load
webElem_month <- remDr$findElement(using = "css", "#cphBody_Mont_list")
opts_month <- webElem_month$selectTag()
opts_month$elements[[x]]$clickElement() # select a different month in each lapply iteration
Sys.sleep(10) # for submit button to become active
webElem_submit <- remDr$findElement(using = "css", "#cphBody_But_Submit")
webElem_submit$clickElement()
page_source <- remDr$getPageSource()
tdf <- read_html(page_source[[1]]) %>%     # read table
html_nodes("table") %>% .[[5]] %>%
html_table(header=T,fill=T, trim=T) %>%
head(-1) # remove the last row which contains average at the bottom of the scraped table
})
remDr$close()
rD$server$stop()
rD <- rsDriver()
rD <- remoteDriver()
rd
rD
install.packages(c("httr", "jsonlite"))
install.packages(c("httr", "jsonlite"))
library(httr)
library(jsonlite)
###############################
rm(list=ls())
library(tidyverse)
library(stringr)
install.packages("selectr")
install.packages("xml2")
install.packages("rvest")
library(xml2)
library(rvest)
library(selectr)
##### Prepapre the list of all commodities
## extarct the commodity name and commodity code on the website
library(httr) url2<-"https://agmarknet.gov.in/SearchCmmMkt.aspx?Tx_Commodity=17&Tx_State=0&Tx_District=0&Tx_Market=0&DateFrom=17-June-2019&DateTo=06-May-2020&Fr_Date=06-Apr-2020&To_Date=06-May-2020&Tx_Trend=2&Tx_CommodityHead=Apple&Tx_StateHead=--Select--&Tx_DistrictHead=--Select--&Tx_MarketHead=--Select--"
library(XML)
response<-GET(url2)
doc= htmlParse(response,useInternalNodes = TRUE)
root<-xmlRoot(doc)
xml_names<-xpathSApply(root,"//option",xmlValue) xml_names t<-xml_names[7:353]
xml_names1<-xpathSApply(root,"//option",xmlAttrs) com1<-matrix(unlist(xml_names1), nrow=length(xml_names1), byrow=F)
t2<-com1[9:356,1] t2<-t2[-which(t2=="selected")]
t<-as.character(t) t2<-as.numeric(t2) com2<-as.data.frame(cbind(t,t2)) com2$t[1]
names(com2)<-c("commodity", "commodity_code") commodity<-gsub(" ", "+", com2$commodity) com2$commodity<-commodity ###All the commodity with the code is stored in the dataset com2 table(com2$commodity) library(dplyr) com2<-as.data.frame(com2) names(com2)
com2=com2[com2$commodity=="Potato",]
##We can choose or take all the commodities in the list
############ For all Dates + all commodities ############### ##start date we denote with c and end date with d #Here Start date will continuously change using loop, end date will always remained constant
###Prepare the date data set in the reqiure date format
dateto<-seq(as.Date("2020-03-01"), as.Date("2020-04-30"), by="days")
##Year-MM-Date format
d<-"30-April-2020"
##End date
dateto[1]nchar(dateto[1])day <-substring(dateto,9,10)
m<-months(as.Date(dateto))
m<-substring(m, 1,3)
y<-format(as.Date(dateto, format="%y-%m-%d"),"%Y")
dateto[1]
dateto<-paste0(day,"-", m, "-", y) dateto
###extract the url of all the excel of all the commodities and all the date ##if you want to change the commodities list or timeperiod , then change the dateto and com2 url<-NA ###URL of the page with start date c and end date d and commodities list com2 price=2 ##type 0 for only price, type=2 for both price and arriavl q
for (i in 1:length(dateto)){
c=dateto[i]
for (j in 1:nrow(com2)) {
a<-com2$commodity_code[j]
b<-as.character(com2$commodity[j])
url2[j]<-paste0("https://agmarknet.gov.in/SearchCmmMkt.aspx?Tx_Commodity","=",a,"&Tx_State=0&Tx_District=0&Tx_Market=0&DateFrom=",c,"&DateTo=", d, "&Fr_Date=", c, "&To_Date=",d, "&Tx_Trend=",price, "&Tx_CommodityHead=", b, "&Tx_StateHead=--Select--&Tx_DistrictHead=--Select--&Tx_MarketHead=--Select--")
url<-cbind(url, url2[j])
}
}
url<-url[-1]
pp<-length(url)
###Data pulling and saving t3<-NA ##Master Excel
comm_name<-rep(com2$commodity, length(dateto))
for(i in 1: pp ){
url2<-url[i]
t<-read_html(url2) t1<-html_nodes(t, "table") %>%
html_table(fill = T)
t2<-as.data.frame(t1[1])
if(nrow(t2)>0 & ncol(t2)>10){t2<-t2[,-c(11:12)]}
if(nrow(t2)>0){t2$crop<-comm_name[i]}
if(nrow(t2)>0){ t3<-as.data.frame(rbind(t2, t3))}
}
t4<-t3 ##2020 t5<-t3 ##2019 t6<-t3 ##2018
final<-as.data.frame(rbind(t4, t5,t6))
write.csv(t4,"price_data_potato_2020.csv",
row.names = F)
write.csv(t5,"price_data_potato_2019.csv", row.names = F)
write.csv(t6,"price_data_potato_2018.csv", row.names = F)
write.csv(final,"price_data_potato_181920.csv", row.names = F)
###################END#############################################
install.packages("selectr")
install.packages("xml2")
install.packages("rvest")
library(tidyverse)
###############################
rm(list=ls())
library(tidyverse)
library(stringr)
install.packages("selectr")
install.packages("xml2")
install.packages("rvest")
library(xml2)
library(rvest)
library(selectr)
install.packages("xml2")
install.packages("rvest")
##### Prepapre the list of all commodities
## extarct the commodity name and commodity code on the website
library(httr) url2<-"https://agmarknet.gov.in/SearchCmmMkt.aspx?Tx_Commodity=17&Tx_State=0&Tx_District=0&Tx_Market=0&DateFrom=17-June-2019&DateTo=06-May-2020&Fr_Date=06-Apr-2020&To_Date=06-May-2020&Tx_Trend=2&Tx_CommodityHead=Apple&Tx_StateHead=--Select--&Tx_DistrictHead=--Select--&Tx_MarketHead=--Select--"
library(XML)
response<-GET(url2)
doc= htmlParse(response,useInternalNodes = TRUE)
root<-xmlRoot(doc)
library(XML)
library(httr)
url2<-"https://agmarknet.gov.in/SearchCmmMkt.aspx?Tx_Commodity=17&Tx_State=0&Tx_District=0&Tx_Market=0&DateFrom=17-June-2019&DateTo=06-May-2020&Fr_Date=06-Apr-2020&To_Date=06-May-2020&Tx_Trend=2&Tx_CommodityHead=Apple&Tx_StateHead=--Select--&Tx_DistrictHead=--Select--&Tx_MarketHead=--Select--"
response<-GET(url2)
doc= htmlParse(response,useInternalNodes = TRUE)
root<-xmlRoot(doc)
xml_names<-xpathSApply(root,"//option",xmlValue) xml_names t<-xml_names[7:353]
xml_names1<-xpathSApply(root,"//option",xmlAttrs) com1<-matrix(unlist(xml_names1), nrow=length(xml_names1), byrow=F)
xml_names<-xpathSApply(root,"//option",xmlValue)
xml_names
t<-xml_names[7:353]
rm(list=ls())
##### Prepapre the list of all commodities
## extarct the commodity name and commodity code on the website
url2<-"https://agmarknet.gov.in/SearchCmmMkt.aspx?Tx_Commodity=17&Tx_State=0&Tx_District=0&Tx_Market=0&DateFrom=17-June-2019&DateTo=06-May-2020&Fr_Date=06-Apr-2020&To_Date=06-May-2020&Tx_Trend=2&Tx_CommodityHead=Apple&Tx_StateHead=--Select--&Tx_DistrictHead=--Select--&Tx_MarketHead=--Select--"
response<-GET(url2)
doc= htmlParse(response,useInternalNodes = TRUE)
root<-xmlRoot(doc)
xml_names<-xpathSApply(root,"//option",xmlValue)
xml_names
t<-xml_names[7:353]
xml_names1<-xpathSApply(root,"//option",xmlAttrs)
com1<-matrix(unlist(xml_names1), nrow=length(xml_names1), byrow=F)
t2<-com1[9:356,1]
t2<-t2[-which(t2=="selected")]
t<-as.character(t)
t2<-as.numeric(t2)
com2<-as.data.frame(cbind(t,t2))
com2$t[1]
names(com2) <-c("commodity", "commodity_code")
commodity<-gsub(" ", "+", com2$commodity)
com2$commodity<-commodity ###All the commodity with the code is stored in the dataset com2 table(com2$commodity) library(dplyr) com2<-as.data.frame(com2) names(com2)
com2=com2[com2$commodity=="Potato",]
##We can choose or take all the commodities in the list
############ For all Dates + all commodities ############### ##start date we denote with c and end date with d #Here Start date will continuously change using loop, end date will always remained constant
###Prepare the date data set in the reqiure date format
dateto<-seq(as.Date("2020-03-01"), as.Date("2020-04-30"), by="days")
##Year-MM-Date format
d<-"30-April-2020"
##End date
dateto[1]nchar(dateto[1])day
<-substring(dateto,9,10)
m<-months(as.Date(dateto))
m<-substring(m, 1,3)
y<-format(as.Date(dateto, format="%y-%m-%d"),"%Y")
dateto[1]
dateto<-paste0(day,"-", m, "-", y)
dateto
###extract the url of all the excel of all the commodities and all the date ##if you want to change the commodities list or timeperiod , then change the dateto and com2 url<-NA ###URL of the page with start date c and end date d and commodities list com2 price=2 ##type 0 for only price, type=2 for both price and arriavl q
for (i in 1:length(dateto)){
c=dateto[i]
for (j in 1:nrow(com2)) {
a<-com2$commodity_code[j]
b<-as.character(com2$commodity[j])
url2[j]<-paste0("https://agmarknet.gov.in/SearchCmmMkt.aspx?Tx_Commodity","=",a,"&Tx_State=0&Tx_District=0&Tx_Market=0&DateFrom=",c,"&DateTo=", d, "&Fr_Date=", c, "&To_Date=",d, "&Tx_Trend=",price, "&Tx_CommodityHead=", b, "&Tx_StateHead=--Select--&Tx_DistrictHead=--Select--&Tx_MarketHead=--Select--")
url<-cbind(url, url2[j])
}
}
url<-url[-1]
pp<-length(url)
###Data pulling and saving t3<-NA ##Master Excel
comm_name<-rep(com2$commodity, length(dateto))
for(i in 1: pp ){
url2<-url[i]
t<-read_html(url2) t1<-html_nodes(t, "table") %>%
html_table(fill = T)
t2<-as.data.frame(t1[1])
if(nrow(t2)>0 & ncol(t2)>10){t2<-t2[,-c(11:12)]}
if(nrow(t2)>0){t2$crop<-comm_name[i]}
if(nrow(t2)>0){ t3<-as.data.frame(rbind(t2, t3))}
}
t4<-t3 ##2020 t5<-t3 ##2019 t6<-t3 ##2018
final<-as.data.frame(rbind(t4, t5,t6))
write.csv(t4,"price_data_potato_2020.csv",
row.names = F)
write.csv(t5,"price_data_potato_2019.csv", row.names = F)
write.csv(t6,"price_data_potato_2018.csv", row.names = F)
write.csv(final,"price_data_potato_181920.csv", row.names = F)
###################END#############################################
rm(list=ls())
url2<-"https://agmarknet.gov.in/SearchCmmMkt.aspx?Tx_Commodity=17&Tx_State=0&Tx_District=0&Tx_Market=0&DateFrom=17-June-2019&DateTo=06-May-2020&Fr_Date=06-Apr-2020&To_Date=06-May-2020&Tx_Trend=2&Tx_CommodityHead=Apple&Tx_StateHead=--Select--&Tx_DistrictHead=--Select--&Tx_MarketHead=--Select--"
response<-GET(url2)
doc= htmlParse(response,useInternalNodes = TRUE)
root<-xmlRoot(doc)
xml_names<-xpathSApply(root,"//option",xmlValue)
xml_names
t<-xml_names[7:353]
xml_names1<-xpathSApply(root,"//option",xmlAttrs)
com1<-matrix(unlist(xml_names1), nrow=length(xml_names1), byrow=F)
t2<-com1[9:356,1]
t2<-t2[-which(t2=="selected")]
t<-as.character(t)
t2<-as.numeric(t2)
com2<-as.data.frame(cbind(t,t2))
com2$t[1]
names(com2) <-c("commodity", "commodity_code")
commodity<-gsub(" ", "+", com2$commodity)
com2$commodity<-commodity ###All the commodity with the code is stored in the dataset com2 table(com2$commodity) library(dplyr) com2<-as.data.frame(com2) names(com2)
com2=com2[com2$commodity=="Potato",]
##We can choose or take all the commodities in the list
############ For all Dates + all commodities ############### ##start date we denote with c and end date with d #Here Start date will continuously change using loop, end date will always remained constant
###Prepare the date data set in the reqiure date format
dateto<-seq(as.Date("2020-03-01"), as.Date("2020-04-30"), by="days")
##Year-MM-Date format
d<-"30-April-2020"
##End date
dateto[1]nchar(dateto[1])day
<-substring(dateto,9,10)
m<-months(as.Date(dateto))
m<-substring(m, 1,3)
y<-format(as.Date(dateto, format="%y-%m-%d"),"%Y")
dateto[1]
dateto<-paste0(day,"-", m, "-", y)
dateto
###extract the url of all the excel of all the commodities and all the date ##if you want to change the commodities list or timeperiod , then change the dateto and com2 url<-NA ###URL of the page with start date c and end date d and commodities list com2 price=2 ##type 0 for only price, type=2 for both price and arriavl q
for (i in 1:length(dateto)){
c=dateto[i]
for (j in 1:nrow(com2)) {
a<-com2$commodity_code[j]
b<-as.character(com2$commodity[j])
url2[j]<-paste0("https://agmarknet.gov.in/SearchCmmMkt.aspx?Tx_Commodity","=",a,"&Tx_State=0&Tx_District=0&Tx_Market=0&DateFrom=",c,"&DateTo=", d, "&Fr_Date=", c, "&To_Date=",d, "&Tx_Trend=",price, "&Tx_CommodityHead=", b, "&Tx_StateHead=--Select--&Tx_DistrictHead=--Select--&Tx_MarketHead=--Select--")
url<-cbind(url, url2[j])
}
}
url<-url[-1]
pp<-length(url)
###Data pulling and saving t3<-NA ##Master Excel
comm_name<-rep(com2$commodity, length(dateto))
for(i in 1: pp ){
url2<-url[i]
t<-read_html(url2) t1<-html_nodes(t, "table") %>%
html_table(fill = T)
t2<-as.data.frame(t1[1])
if(nrow(t2)>0 & ncol(t2)>10){
t2<-t2[,-c(11:12)]
}
if(nrow(t2)>0){
t2$crop<-comm_name[i]
}
if(nrow(t2)>0){
t3<-as.data.frame(rbind(t2, t3))
}
}
url<-url[-1]
url <-url[-1]
url<-NA
###URL of the page with start date c and end date d and commodities list com2 price=2 ##type 0 for only price, type=2 for both price and arriavl q
for (i in 1:length(dateto)){
c=dateto[i]
for (j in 1:nrow(com2)) {
a<-com2$commodity_code[j]
b<-as.character(com2$commodity[j])
url2[j]<-paste0("https://agmarknet.gov.in/SearchCmmMkt.aspx?Tx_Commodity","=",a,"&Tx_State=0&Tx_District=0&Tx_Market=0&DateFrom=",c,"&DateTo=", d, "&Fr_Date=", c, "&To_Date=",d, "&Tx_Trend=",price, "&Tx_CommodityHead=", b, "&Tx_StateHead=--Select--&Tx_DistrictHead=--Select--&Tx_MarketHead=--Select--")
url<-cbind(url, url2[j])
}
}
url <- url[-1]
##### Prepapre the list of all commodities
## extarct the commodity name and commodity code on the website
url2<-"https://agmarknet.gov.in/SearchCmmMkt.aspx?Tx_Commodity=17&Tx_State=0&Tx_District=0&Tx_Market=0&DateFrom=17-June-2019&DateTo=06-May-2020&Fr_Date=06-Apr-2020&To_Date=06-May-2020&Tx_Trend=2&Tx_CommodityHead=Apple&Tx_StateHead=--Select--&Tx_DistrictHead=--Select--&Tx_MarketHead=--Select--"
response<-GET(url2)
doc= htmlParse(response,useInternalNodes = TRUE)
root<-xmlRoot(doc)
xml_names<-xpathSApply(root,"//option",xmlValue)
xml_names
t<-xml_names[7:353]
xml_names1<-xpathSApply(root,"//option",xmlAttrs)
com1<-matrix(unlist(xml_names1), nrow=length(xml_names1), byrow=F)
t2<-com1[9:356,1]
t2<-t2[-which(t2=="selected")]
t<-as.character(t)
t2<-as.numeric(t2)
com2<-as.data.frame(cbind(t,t2))
com2$t[1]
names(com2) <-c("commodity", "commodity_code")
commodity<-gsub(" ", "+", com2$commodity)
com2$commodity<-commodity ###All the commodity with the code is stored in the dataset com2 table(com2$commodity) library(dplyr) com2<-as.data.frame(com2) names(com2)
com2=com2[com2$commodity=="Potato",]
##We can choose or take all the commodities in the list
############ For all Dates + all commodities ############### ##start date we denote with c and end date with d #Here Start date will continuously change using loop, end date will always remained constant
###Prepare the date data set in the reqiure date format
dateto<-seq(as.Date("2020-03-01"), as.Date("2020-04-30"), by="days")
##Year-MM-Date format
d<-"30-April-2020"
##End date
dateto[1]nchar(dateto[1])day
<-substring(dateto,9,10)
m<-months(as.Date(dateto))
m<-substring(m, 1,3)
y<-format(as.Date(dateto, format="%y-%m-%d"),"%Y")
dateto[1]
dateto<-paste0(day,"-", m, "-", y)
dateto
###extract the url of all the excel of all the commodities and all the date
##if you want to change the commodities list or timeperiod , then change the dateto and com2
url<-NA
###URL of the page with start date c and end date d and commodities list com2 price=2 ##type 0 for only price, type=2 for both price and arriavl q
for (i in 1:length(dateto)){
c=dateto[i]
for (j in 1:nrow(com2)) {
a<-com2$commodity_code[j]
b<-as.character(com2$commodity[j])
url2[j]<-paste0("https://agmarknet.gov.in/SearchCmmMkt.aspx?Tx_Commodity","=",a,"&Tx_State=0&Tx_District=0&Tx_Market=0&DateFrom=",c,"&DateTo=", d, "&Fr_Date=", c, "&To_Date=",d, "&Tx_Trend=",price, "&Tx_CommodityHead=", b, "&Tx_StateHead=--Select--&Tx_DistrictHead=--Select--&Tx_MarketHead=--Select--")
url<-cbind(url, url2[j])
}
}
url <- url[-1]
pp<-length(url)
###Data pulling and saving t3<-NA ##Master Excel
comm_name<-rep(com2$commodity, length(dateto))
for(i in 1: pp ){
url2<-url[i]
t<-read_html(url2) t1<-html_nodes(t, "table") %>%
html_table(fill = T)
t2<-as.data.frame(t1[1])
if(nrow(t2)>0 & ncol(t2)>10){
t2<-t2[,-c(11:12)]
}
if(nrow(t2)>0){
t2$crop<-comm_name[i]
}
if(nrow(t2)>0){
t3<-as.data.frame(rbind(t2, t3))
}
}
t4<-t3 ##2020 t5<-t3 ##2019 t6<-t3 ##2018
final<-as.data.frame(rbind(t4, t5,t6))
0.051/100
0.040/100
0.041/100
rm(list=ls())
options(scipen=3)
# Loading excel files
library(readxl)
library(fixest)
library(dplyr)
library(ggplot2)
library(ggthemes)
library(stargazer)
library(patchwork)
my_theme <- function(base_size = 12,
base_family = "") {
theme_minimal(base_size = base_size,
base_family = base_family) %+replace%
theme(
panel.grid.minor = element_blank(),
panel.grid.major.x = element_blank(),
panel.grid.major.y  =  element_line(
colour = "#c9c0b7",
linetype = "dotted",
size = 0.5),
axis.ticks = element_line(size = .5, colour = "#c9c0b7"),
axis.ticks.x = element_blank(),
axis.line = element_line(
size = 0.5,
colour = "#c9c0b7",
linetype = "solid"),
axis.line.y = element_blank(),
axis.text.y = element_text(colour = "black",
margin = margin(r = 2),
hjust = 1),
axis.text.x = element_text(colour = "black"),
legend.title = element_blank(),
complete = TRUE)
}
theme_set(my_theme(base_size = 15))
mypink <- "#e95984"
mypurple <- "#b649ff"
cseblue <- "#16926d"
# Setting working directory
setwd("C:/Users/admin/cse Dropbox/Zaeen de Souza/Files From Deepti/Problem Sets - Latex, Code, Rmd/econometric-methods/Chapters/Chapter 12 Instrument Variables, IV Weak Instruments/Dataset")
# Loading the data as 'pset_data'
pset_data1 <- read_excel("fertility.xlsx")
pset_data2 <- read_excel("WeakInstrument.xlsx")
# latex output - table editing for etable()
set_rules = function(x, heavy, light){
# x: the character vector returned by etable
tex2add = ""
if(!missing(heavy)){
tex2add = paste0("\\setlength\\heavyrulewidth{", heavy, "}\n")
}
if(!missing(light)){
tex2add = paste0(tex2add, "\\setlength\\lightrulewidth{", light, "}\n")
}
if(nchar(tex2add) > 0){
x[x == "%start:tab\n"] = tex2add
}
x
}
# fixest dictionry for table labels in for etable()
setFixest_dict(c(morekids = "$\\geq$ 2 Children",
boy1st = "1st child male",
boy2nd = "2nd child male",
samesex = "1st two children same sex",
agem1 = "Mothers Age (Years",
black = "Black",
hispan = "Hispanic",
othrace = "Other Race",
weeksm1 = "Weeks Worked (1979)"))
# for etable() styling
setFixest_etable(style.tex = style.tex(main = "base",
depvar.title = "",
model.title = "",
var.title = "\\midrule \\",
yesNo = "$\\checkmark$",
fixef.title = "\\midrule",
fixef.suffix = " Fixed Effects",
notes.title = "\\medskip \\textbf{Notes:}",
stats.title = "\\midrule"))
table(pset_data1$morekids)
View(pset_data1)
6.8+34.6
2/5
3/10
est_iv = feols(weeksm1 ~ agem1 | morekids ~ samesex, pset_data1)
summary(est_iv)
est_iv = feols(weeksm1 ~ 1 | morekids ~ samesex, pset_data1)
summary(est_iv)
0.346+0.68
0.346+0.068
2/5
